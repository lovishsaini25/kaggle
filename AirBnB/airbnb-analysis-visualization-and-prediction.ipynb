{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lovishsaini25/airbnb-analysis-visualization-and-prediction?scriptVersionId=144007197\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Breakdown of the notebook**:\n\n**1: Data Loading and Exploration**\n- Load the dataset into a pandas DataFrame.\n- Explore the dataset to understand its structure and content.\n- Check for missing values and handle them if necessary.\n- Clean and preprocess the data as needed.\n\n**2: Data Visualization and Exploration**\n- Perform data visualization to gain insights into the dataset.\n- Create visualizations such as histograms, scatter plots, and box plots to understand the distribution of variables and relationships between them.\n- Use libraries like Matplotlib and Seaborn for data visualization.\n\n**3: Data Preprocessing**\n- Select relevant features (columns) for the analysis.\n- Encode categorical variables if needed (e.g., one-hot encoding).\n- Split the data into training and test sets for model evaluation.\n\n**4: Model Selection and Training**\n- Choose machine learning models for the analysis (e.g., Decision Tree, Random Forest, XGBoost).\n- Train the selected models on the training data.\n\n**5: Model Evaluation**\n- Evaluate model performance using appropriate metrics (e.g., RMSE, R2 score).\n- Check for overfitting by comparing performance on training and test data.\n- Tune hyperparameters to improve model performance.\n\n**6: Interpretation and Insights**\n- Interpret model results and evaluate the importance of features.\n- Use insights from the analysis to make informed decisions or draw conclusions.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-23T21:33:58.96392Z","iopub.execute_input":"2023-09-23T21:33:58.964362Z","iopub.status.idle":"2023-09-23T21:33:59.496421Z","shell.execute_reply.started":"2023-09-23T21:33:58.964326Z","shell.execute_reply":"2023-09-23T21:33:59.495003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndf = pd.read_csv('/kaggle/input/us-airbnb-open-data/AB_US_2023.csv')\n# data_2020 = pd.read_csv('/kaggle/input/us-airbnb-open-data/AB_US_2020.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:33:59.498777Z","iopub.execute_input":"2023-09-23T21:33:59.499435Z","iopub.status.idle":"2023-09-23T21:34:02.306976Z","shell.execute_reply.started":"2023-09-23T21:33:59.499399Z","shell.execute_reply":"2023-09-23T21:34:02.305397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:02.309534Z","iopub.execute_input":"2023-09-23T21:34:02.309999Z","iopub.status.idle":"2023-09-23T21:34:02.348177Z","shell.execute_reply.started":"2023-09-23T21:34:02.309954Z","shell.execute_reply":"2023-09-23T21:34:02.347345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:02.349586Z","iopub.execute_input":"2023-09-23T21:34:02.349919Z","iopub.status.idle":"2023-09-23T21:34:02.357677Z","shell.execute_reply.started":"2023-09-23T21:34:02.34989Z","shell.execute_reply":"2023-09-23T21:34:02.356476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:02.362827Z","iopub.execute_input":"2023-09-23T21:34:02.363405Z","iopub.status.idle":"2023-09-23T21:34:02.372691Z","shell.execute_reply.started":"2023-09-23T21:34:02.363352Z","shell.execute_reply":"2023-09-23T21:34:02.371447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<table style=\"border-collapse: collapse; width: 70%; border: 2px solid black;\">\n  <tr>\n    <th style=\"border: 1px solid black; padding: 8px;\">Column</th>\n    <th style=\"border: 1px solid black; padding: 8px;\">Description</th>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">id</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Airbnb's unique identifier for the listing</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">name</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Name of the listing</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">host_id</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Airbnb host's unique identifier</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">host_name</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Name of the host</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">neighbourhood_group</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">The neighbourhood group as geocoded using the latitude and longitude against neighborhoods as defined by open or public digital shapefiles.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">neighbourhood</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">The neighbourhood as geocoded using the latitude and longitude against neighborhoods as defined by open or public digital shapefiles.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">latitude</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Latitude in the World Geodetic System (WGS84) projection</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">longitude</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Longitude in the World Geodetic System (WGS84) projection</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">room_type</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Type of room (e.g., entire home, private room, shared room)</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">price</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Daily price in local currency (Note: $ sign may be used regardless of locale)</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">minimum_nights</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Minimum number of nights required for the listing (calendar rules may vary)</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">number_of_reviews</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Total number of reviews the listing has received</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">last_review</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Date of the last/newest review</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">calculated_host_listings_count</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Number of listings the host has in the current scrape, in the city/region geography</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">availability_365</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Availability of the listing x days in the future as determined by the calendar. Note: A listing may be available because it has been booked by a guest or blocked by the host.</td>\n  </tr>\n  <tr>\n    <td style=\"border: 1px solid black; padding: 8px;\">number_of_reviews_ltm</td>\n    <td style=\"border: 1px solid black; padding: 8px;\">Number of reviews the listing has received in the last 12 months</td>\n  </tr>\n</table>\n","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:02.374853Z","iopub.execute_input":"2023-09-23T21:34:02.376042Z","iopub.status.idle":"2023-09-23T21:34:02.570827Z","shell.execute_reply.started":"2023-09-23T21:34:02.376001Z","shell.execute_reply":"2023-09-23T21:34:02.56956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:02.572644Z","iopub.execute_input":"2023-09-23T21:34:02.573058Z","iopub.status.idle":"2023-09-23T21:34:02.722403Z","shell.execute_reply.started":"2023-09-23T21:34:02.573024Z","shell.execute_reply":"2023-09-23T21:34:02.721287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. **Counts:**\n   - The dataset contains 232,147 records for all columns, indicating that there is no missing data in any of the columns.\n\n2. **Hosts and Listings:**\n   - The range of `host_id` values is quite extensive, ranging from a minimum of 23 to a maximum of 506,938,400.\n   - The dataset includes listings across various geographic locations, with `latitude` values ranging from approximately 25.96 to 47.73 and `longitude` values ranging from approximately -123.09 to -70.99.\n\n3. **Pricing:**\n   - The `price` column has a wide range of values, with a minimum of 0 and a maximum of 100,000. The mean price is approximately *USD* 259.47, but the standard deviation is quite high (approximately *USD* 1024.65), indicating a significant variability in listing prices.\n\n4. **Minimum Nights and Availability:**\n   - The `minimum_nights` column ranges from a minimum of 1 night to a maximum of 1,250 nights, with a mean of approximately 13.50 nights.\n   - The `availability_365` column ranges from 0 to 365 days, indicating the availability of listings throughout the year.\n\n5. **Reviews:**\n   - The `number_of_reviews` column has a wide range, with a minimum of 0 and a maximum of 3,091 reviews. The mean number of reviews is approximately 40.92, but the standard deviation is relatively high (approximately 80.65), suggesting variations in the number of reviews.\n   - The `reviews_per_month` column ranges from a minimum of 0.01 to a maximum of 101.42, with a mean of approximately 1.64. This column provides information about the average number of reviews per month for each listing.\n\n6. **Host Listings:**\n   - The `calculated_host_listings_count` column shows the number of listings each host has in the current scrape. The range is from 1 to 1,003 listings, with a mean of approximately 29.88 listings per host.\n\n7. **Availability Within the Last 12 Months:**\n   - The `number_of_reviews_ltm` column represents the number of reviews each listing has received in the last 12 months. It ranges from 0 to 1,314 reviews, with a mean of approximately 11.69 reviews.","metadata":{}},{"cell_type":"markdown","source":"**Potential issues**\n\n1. **Outliers:**\n   - The presence of outliers in columns like `price`, `minimum_nights`, `number_of_reviews`, `reviews_per_month`, `calculated_host_listings_count`, and `number_of_reviews_ltm` is evident from the large standard deviations and the significant differences between the 75th percentile and the maximum values. Let's investigate and decide whether to remove these outliers.\n\n2. **Zero Minimum Nights:**\n   - The `minimum_nights` column has a minimum value of 0, which does not make sense for a minimum stay requirement. We will validate these records to determine if they are valid or if they need to be cleaned. Maybe the 0 means None.\n\n3. **Missing Data:**\n   - The column `reviews_per_month` has missing data, as indicated by the count being less than the total number of records.\n\n4. **Geographic Outliers:**\n   - The latitude and longitude columns may contain data points that could potentially be outliers.","metadata":{}},{"cell_type":"code","source":"# Compute the sum of missing values for each column\nmissing_sum = df.isnull().sum()\n\n# Compute the percentage of missing values for each column\nmissing_percentage = (df.isnull().sum() / len(df)) * 100\n\n# Create a DataFrame to display the results\nmissing_info = pd.DataFrame({'Missing Values': missing_sum, 'Percentage Missing': missing_percentage})\n\n# Sort the DataFrame by the number of missing values in descending order\nmissing_info.sort_values(by='Missing Values', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:02.724916Z","iopub.execute_input":"2023-09-23T21:34:02.725319Z","iopub.status.idle":"2023-09-23T21:34:03.067276Z","shell.execute_reply.started":"2023-09-23T21:34:02.725286Z","shell.execute_reply":"2023-09-23T21:34:03.066075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Cleaning Strategy**\n1. **Deletion:**\n    - **name/host name** The number of missing values for name/host name is very small and won't significantly impact our analysis, we can choose to remove the rows with missing values. These columns contain text data (names). Handling missing text data can be a bit more complex.\n        - We can impute missing names with a placeholder value like \"Unknown\" or \"Anonymous.\" But, we will prefer to remove them since they are a very small percentage of the total data and names are not critical for our analysis\n    - **neighbourhood_group:** The neighbourhood_group is not a critical feature for our analysis and the missing values are large, we may choose to remove this column from the dataset.\n\n2. **Imputation:** You can impute missing values using various techniques depending on the data type. For numeric columns (e.g., price, minimum_nights), you can fill missing values with the mean, median, or a specific value that makes sense in the context. For categorical columns (e.g., room_type), you can use the mode (most frequent category) to fill missing values.\n    - **last_review and reviews_per_month:** We can impute missing values in these columns with a specific value or date that indicates missing data. Alternatively, We can use statistical methods to estimate missing values based on the distribution of the existing data.","metadata":{}},{"cell_type":"code","source":"# Drop rows with null values in 'host_name' and 'name' columns\ndf.dropna(subset=['host_name', 'name'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:03.069241Z","iopub.execute_input":"2023-09-23T21:34:03.06988Z","iopub.status.idle":"2023-09-23T21:34:03.180055Z","shell.execute_reply.started":"2023-09-23T21:34:03.069847Z","shell.execute_reply":"2023-09-23T21:34:03.178718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:03.181991Z","iopub.execute_input":"2023-09-23T21:34:03.182328Z","iopub.status.idle":"2023-09-23T21:34:03.35423Z","shell.execute_reply.started":"2023-09-23T21:34:03.1823Z","shell.execute_reply":"2023-09-23T21:34:03.352823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This cell was time consuming and compute intensive. Hence, commented it out. As a replacenment using the below code\n# import folium\n\n# # Create a map of listings\n# m = folium.Map(location=[df['latitude'].mean(), df['longitude'].mean()], zoom_start=12)\n# for index, row in df.iterrows():\n#     if index % 25000 == 0:\n#         print(index)\n#     folium.Marker([row['latitude'], row['longitude']], tooltip=row['name']).add_to(m)\n# m","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:03.355822Z","iopub.execute_input":"2023-09-23T21:34:03.356212Z","iopub.status.idle":"2023-09-23T21:34:03.363718Z","shell.execute_reply.started":"2023-09-23T21:34:03.356182Z","shell.execute_reply":"2023-09-23T21:34:03.362213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from folium.plugins import MarkerCluster\n\n# m = folium.Map(location=[df['latitude'].mean(), df['longitude'].mean()], zoom_start=12)\n# marker_cluster = MarkerCluster().add_to(m)\n\n# for index, row in df.iterrows():\n#     folium.Marker([row['latitude'], row['longitude']], tooltip=row['name']).add_to(marker_cluster)\n\n# # Save the map as a PNG image (static map takes up less space)\n# m.save('airbnb_listings_map.png')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:03.365843Z","iopub.execute_input":"2023-09-23T21:34:03.366567Z","iopub.status.idle":"2023-09-23T21:34:03.381344Z","shell.execute_reply.started":"2023-09-23T21:34:03.366503Z","shell.execute_reply":"2023-09-23T21:34:03.380055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Cluster Markers**: Folium provides marker clustering functionality, which groups nearby markers into clusters when the map is zoomed out. This can improve performance and make the map more user-friendly. You can use MarkerCluster from Folium to achieve this.","metadata":{}},{"cell_type":"code","source":"# we wanted to ensure using folium if all the data points lies within USA, however, it was taking longer to execute.\n# Hence, used this alternative to perform the task\n# We can see that 100% of the data records lies within USA\n\ndef is_within_usa(latitude, longitude):\n    usa_bounding_box = {\n        'min_lat': 24.396308,\n        'max_lat': 49.384358,\n        'min_lon': -125.000000,\n        'max_lon': -66.934570\n    }\n    if (usa_bounding_box['min_lat'] <= latitude <= usa_bounding_box['max_lat'] and\n        usa_bounding_box['min_lon'] <= longitude <= usa_bounding_box['max_lon']):\n        return True\n    else:\n        return False\n\nprint(len(df.apply(lambda row: is_within_usa(row['latitude'], row['longitude']), axis=1)) / len(df)*100)\ndf = df[df.apply(lambda row: is_within_usa(row['latitude'], row['longitude']), axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:03.383674Z","iopub.execute_input":"2023-09-23T21:34:03.384176Z","iopub.status.idle":"2023-09-23T21:34:11.74338Z","shell.execute_reply.started":"2023-09-23T21:34:03.384134Z","shell.execute_reply":"2023-09-23T21:34:11.741876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\n\n# Identify and remove price outliers using Z-score\nz_scores = np.abs(stats.zscore(df['price']))\nprint(f'Percentage of data retained: {len(df[(z_scores < 3)])/len(df)* 100}%')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:11.749597Z","iopub.execute_input":"2023-09-23T21:34:11.750017Z","iopub.status.idle":"2023-09-23T21:34:11.799187Z","shell.execute_reply.started":"2023-09-23T21:34:11.749985Z","shell.execute_reply":"2023-09-23T21:34:11.798026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a feature for the number of days since the last review\nfrom datetime import datetime\ndf['last_review'] = pd.to_datetime(df['last_review'])\ndf['days_since_last_review'] = (datetime.now() - df['last_review']).dt.days\n# df = df.drop(columns=['last_review'])\ndf['days_since_last_review'].fillna(-1, inplace=True)\ndf['days_since_last_review'] = df['days_since_last_review'].astype(int)\n\n# Price itself itn't a good feature\ndf['price_per_night'] = df['price'] / df['minimum_nights']\n\n# reviews_ratio might be useful too to see how eagerly people review the site\ndf['reviews_ratio'] = df['number_of_reviews_ltm'] / df['number_of_reviews']\n\n# Binning 'availability_365' into 4 bins\ndf['availability'] = pd.cut(df['availability_365'], bins=[0, 90, 180, 270, 365], labels=['low', 'medium', 'high', 'very high'])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:11.800785Z","iopub.execute_input":"2023-09-23T21:34:11.802152Z","iopub.status.idle":"2023-09-23T21:34:11.910025Z","shell.execute_reply.started":"2023-09-23T21:34:11.802099Z","shell.execute_reply":"2023-09-23T21:34:11.908703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a feature representing the interaction between 'price' and 'reviews_ratio'\ndf['price_reviews_ratio'] = df['price'] * df['reviews_ratio']","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:11.91148Z","iopub.execute_input":"2023-09-23T21:34:11.911881Z","iopub.status.idle":"2023-09-23T21:34:11.920935Z","shell.execute_reply.started":"2023-09-23T21:34:11.911848Z","shell.execute_reply":"2023-09-23T21:34:11.919123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npercentiles = [25, 50, 75, 90, 95]  \n\npercentiles.extend([i/10 for i in range(990, 1000, 1)] + [100])\n\n# Calculate the percentiles of the 'price' column\nprice_percentiles = np.percentile(df['price_per_night'], percentiles)\n\n# Print the calculated percentiles\nfor percentile, value in zip(percentiles, price_percentiles):\n    print(f'{percentile}th Percentile: ${value:.2f}')\n\n# The price of $7k sseems to be too high. Hence, I am droping it","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:11.922745Z","iopub.execute_input":"2023-09-23T21:34:11.923511Z","iopub.status.idle":"2023-09-23T21:34:11.94088Z","shell.execute_reply.started":"2023-09-23T21:34:11.923474Z","shell.execute_reply":"2023-09-23T21:34:11.939614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['price_per_night'] < 6900]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:11.94274Z","iopub.execute_input":"2023-09-23T21:34:11.944082Z","iopub.status.idle":"2023-09-23T21:34:11.994375Z","shell.execute_reply.started":"2023-09-23T21:34:11.944037Z","shell.execute_reply":"2023-09-23T21:34:11.993098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentiles = [25, 50, 75, 90, 95]  \n\npercentiles.extend([i/10 for i in range(990, 1000, 1)] + [100])\n\n# Calculate the percentiles of the 'price' column\nprice_percentiles = np.percentile(df['price'], percentiles)\n\n# Print the calculated percentiles\nfor percentile, value in zip(percentiles, price_percentiles):\n    print(f'{percentile}th Percentile: ${value:.2f}')\n\n# Still the price seems to be at the higher end\ndf = df[df['price'] < 10000]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:11.996833Z","iopub.execute_input":"2023-09-23T21:34:11.99726Z","iopub.status.idle":"2023-09-23T21:34:12.062349Z","shell.execute_reply.started":"2023-09-23T21:34:11.997227Z","shell.execute_reply":"2023-09-23T21:34:12.060842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentiles = [25, 50, 75, 90, 95]  \n\npercentiles.extend([i/10 for i in range(990, 1000, 1)] + [100])\n\n# Calculate the percentiles of the 'price' column\nprice_percentiles = np.percentile(df['minimum_nights'], percentiles)\n\n# Print the calculated percentiles\nfor percentile, value in zip(percentiles, price_percentiles):\n    print(f'{percentile}th Percentile: {value:.2f}')\n\n# It is strange to observe that a site has to be atleast booked for an entire year\n# 180 days are fine too but 365 days are strange to me. However, we will keep it\n# There can be a possibility that a site is rented as a paying guest for an entire year on lease","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.064399Z","iopub.execute_input":"2023-09-23T21:34:12.064769Z","iopub.status.idle":"2023-09-23T21:34:12.077592Z","shell.execute_reply.started":"2023-09-23T21:34:12.064739Z","shell.execute_reply":"2023-09-23T21:34:12.076157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set display options for pandas DataFrames\npd.set_option('display.max_columns', None)  # Display all columns\npd.set_option('display.max_colwidth', None)  # Display full column width (no truncation)\n\ndf[df['minimum_nights'] == 365].head(5)\n\n# There are substantial records, hence it might be incorrect to remove it.\n# even, such kind of data can be useful to analyze","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.079503Z","iopub.execute_input":"2023-09-23T21:34:12.081891Z","iopub.status.idle":"2023-09-23T21:34:12.116253Z","shell.execute_reply.started":"2023-09-23T21:34:12.081839Z","shell.execute_reply":"2023-09-23T21:34:12.115248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['minimum_nights'] == 0].head(5)\n\n# earlier, we got minimum value for a night stay is zero. But, it seems like it is deleted by us\n# Hence, we don't have any faulty zero minimum nights","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.117721Z","iopub.execute_input":"2023-09-23T21:34:12.119042Z","iopub.status.idle":"2023-09-23T21:34:12.138888Z","shell.execute_reply.started":"2023-09-23T21:34:12.118978Z","shell.execute_reply":"2023-09-23T21:34:12.137329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['minimum_nights'] > 365].head(5)\n\n# It is strange but let's keep it as it is","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.140372Z","iopub.execute_input":"2023-09-23T21:34:12.140945Z","iopub.status.idle":"2023-09-23T21:34:12.169297Z","shell.execute_reply.started":"2023-09-23T21:34:12.140911Z","shell.execute_reply":"2023-09-23T21:34:12.168248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have resolved all the potential issues. Let's try to describe the data again","metadata":{}},{"cell_type":"code","source":"df.describe()\n\n# -1 in days_since_last_review if because last reviews for them is NaT","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.170614Z","iopub.execute_input":"2023-09-23T21:34:12.171153Z","iopub.status.idle":"2023-09-23T21:34:12.426444Z","shell.execute_reply.started":"2023-09-23T21:34:12.171122Z","shell.execute_reply":"2023-09-23T21:34:12.42492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.columns)\n\ndf = df.drop(columns=['price_reviews_ratio', 'price_per_night'])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.42808Z","iopub.execute_input":"2023-09-23T21:34:12.428455Z","iopub.status.idle":"2023-09-23T21:34:12.472112Z","shell.execute_reply.started":"2023-09-23T21:34:12.428422Z","shell.execute_reply":"2023-09-23T21:34:12.470339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nnumeric_columns = ['minimum_nights', 'number_of_reviews', 'reviews_per_month',\n                   'calculated_host_listings_count',\n                   'number_of_reviews_ltm', 'days_since_last_review', 'reviews_ratio']\n\n# Create a StandardScaler instance\nscaler = StandardScaler()\n\n# Apply the standardization to the selected numeric columns\ndf[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.474352Z","iopub.execute_input":"2023-09-23T21:34:12.474851Z","iopub.status.idle":"2023-09-23T21:34:12.651085Z","shell.execute_reply.started":"2023-09-23T21:34:12.474806Z","shell.execute_reply":"2023-09-23T21:34:12.649471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To predict the `price` column, we'll nned to select features that are likely to have a significant impact on the price of a listing. By intuition, we think the below columns can be helpful to predict `price`:\n\n1. **room_type**: The type of room (e.g., entire home, private room, shared room) can significantly affect the price.\n\n2. **minimum_nights**: The minimum number of nights required for the listing can influence pricing.\n\n3. **number_of_reviews**: The number of reviews can reflect the popularity of the listing and may correlate with price.\n\n4. **reviews_per_month**: The rate of new reviews per month can indicate the ongoing appeal of the listing.\n\n5. **calculated_host_listings_count**: The number of listings the host has can impact pricing.\n\n6. **availability_365**: The availability of the listing throughout the year may affect price.\n\n7. **number_of_reviews_ltm**: The number of reviews in the last 12 months can provide recent feedback on the listing.\n\n8. **city**: The location (city) of the listing can have a significant impact on the price.\n\n9. **neighbourhood** and **neighbourhood_group**: The neighborhood and neighborhood group can also be used for location-based analysis.","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix\nnumeric_columns.append('price')\ncorrelation_matrix = df[numeric_columns].corr()\n\n# Select features with strong correlations to 'price'\nstrong_correlations = correlation_matrix['price'].abs() > 0.2\n\n# Get the names of selected features\nselected_features = correlation_matrix.index[strong_correlations].tolist()\n\n# Print the selected features\nprint(\"Selected Features:\")\nprint(selected_features)\n\n#Get Correlation between different variables\nplt.figure(figsize=(18,12))\nsns.heatmap(correlation_matrix*100, annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:12.653157Z","iopub.execute_input":"2023-09-23T21:34:12.653683Z","iopub.status.idle":"2023-09-23T21:34:13.57953Z","shell.execute_reply.started":"2023-09-23T21:34:12.653636Z","shell.execute_reply":"2023-09-23T21:34:13.57777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.get_dummies(df, columns=['room_type', 'neighbourhood_group'], drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:13.581255Z","iopub.execute_input":"2023-09-23T21:34:13.581665Z","iopub.status.idle":"2023-09-23T21:34:13.588558Z","shell.execute_reply.started":"2023-09-23T21:34:13.581633Z","shell.execute_reply":"2023-09-23T21:34:13.586484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Interaction features - Feature engineering\ndf['reviews_times_availability'] = df['number_of_reviews'] * df['availability_365']\ndf['host_experience'] = df['calculated_host_listings_count'] * df['reviews_per_month']\n# I assumed that the site with more reviews is popular and if the availability is high it isn't popular\ndf['popularity'] = df['number_of_reviews'] / df['availability_365']\ndf['booking_flexibility'] = df['minimum_nights'] / df['availability_365']\n\nneighborhood_avg_price = df.groupby('neighbourhood')['price'].transform('mean')\ndf['neighborhood_price_index'] = df['price'] / neighborhood_avg_price\n\n\nskewed_features = ['number_of_reviews', 'reviews_per_month']\nfor feature in skewed_features:\n    df[feature] = np.log1p(df[feature])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:13.59043Z","iopub.execute_input":"2023-09-23T21:34:13.590916Z","iopub.status.idle":"2023-09-23T21:34:13.661887Z","shell.execute_reply.started":"2023-09-23T21:34:13.590881Z","shell.execute_reply":"2023-09-23T21:34:13.660596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_columns.extend(['reviews_times_availability',\n                        'host_experience',\n                        'popularity',\n                        'booking_flexibility',\n                        'neighborhood_price_index']\n                      )\n\n# Calculate the correlation matrix\ncorrelation_matrix = df[numeric_columns].corr()\n\n# Select features with strong correlations to 'price'\nstrong_correlations = correlation_matrix['price'].abs() >= 0.025\n\n# Get the names of selected features\nselected_features = correlation_matrix.index[strong_correlations].tolist()\n\n# Print the selected features\nprint(\"Selected Features:\")\nprint(selected_features)\n\n#Get Correlation between different variables\nplt.figure(figsize=(18,12))\nsns.heatmap(correlation_matrix*100, annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:13.665718Z","iopub.execute_input":"2023-09-23T21:34:13.66622Z","iopub.status.idle":"2023-09-23T21:34:15.05597Z","shell.execute_reply.started":"2023-09-23T21:34:13.666184Z","shell.execute_reply":"2023-09-23T21:34:15.054337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[selected_features].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:15.058201Z","iopub.execute_input":"2023-09-23T21:34:15.058728Z","iopub.status.idle":"2023-09-23T21:34:15.242422Z","shell.execute_reply.started":"2023-09-23T21:34:15.058682Z","shell.execute_reply":"2023-09-23T21:34:15.240949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Outliers\nlower_bound = .25\nupper_bound = .75\ndf = df[df['price'].between(df['price'].quantile(lower_bound), df['price'].quantile(upper_bound))]\ndf = df[df['number_of_reviews'] > 0]\ndf = df[df['calculated_host_listings_count'] < 10]\ndf = df[df['number_of_reviews'] < 200]\ndf = df[df['minimum_nights'] < 10]\ndf = df[df['reviews_per_month'] < 5]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:15.244112Z","iopub.execute_input":"2023-09-23T21:34:15.244594Z","iopub.status.idle":"2023-09-23T21:34:15.358506Z","shell.execute_reply.started":"2023-09-23T21:34:15.244551Z","shell.execute_reply":"2023-09-23T21:34:15.357104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[selected_features].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:15.360668Z","iopub.execute_input":"2023-09-23T21:34:15.361058Z","iopub.status.idle":"2023-09-23T21:34:15.419207Z","shell.execute_reply.started":"2023-09-23T21:34:15.361029Z","shell.execute_reply":"2023-09-23T21:34:15.417773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\n# Select the features and target variable\nselected_features = [\n    'minimum_nights',\n    'number_of_reviews',\n    'number_of_reviews_ltm',\n    'days_since_last_review',\n    'reviews_times_availability'\n]\nX = df[selected_features]\ny = df['price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Decision Tree Regressor\ndt_model = DecisionTreeRegressor(random_state=42)\ndt_param_grid = {\n    'max_depth': [None, 5, 10, 20],  # Max depth of the tree\n    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n}\ndt_grid_search = GridSearchCV(dt_model, dt_param_grid, cv=5, scoring='neg_mean_squared_error')\ndt_grid_search.fit(X_train, y_train)\nbest_dt_model = dt_grid_search.best_estimator_\ndt_mse = -cross_val_score(best_dt_model, X, y, cv=5, scoring='neg_mean_squared_error')\ndt_rmse = np.sqrt(dt_mse.mean())","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:15.421092Z","iopub.execute_input":"2023-09-23T21:34:15.421476Z","iopub.status.idle":"2023-09-23T21:34:22.328787Z","shell.execute_reply.started":"2023-09-23T21:34:15.421446Z","shell.execute_reply":"2023-09-23T21:34:22.327385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Random Forest Regressor\n# rf_model = RandomForestRegressor(random_state=42)\n# rf_param_grid = {\n#     'n_estimators': [100, 200],  # Number of trees in the forest\n#     'max_depth': [None, 5, 10]  # Max depth of individual trees\n# }\n# rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='neg_mean_squared_error')\n# rf_grid_search.fit(X_train, y_train)\n# best_rf_model = rf_grid_search.best_estimator_\n# rf_mse = -cross_val_score(best_rf_model, X, y, cv=5, scoring='neg_mean_squared_error')\n# rf_rmse = np.sqrt(rf_mse.mean())","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:22.330709Z","iopub.execute_input":"2023-09-23T21:34:22.331103Z","iopub.status.idle":"2023-09-23T21:34:22.339149Z","shell.execute_reply.started":"2023-09-23T21:34:22.331069Z","shell.execute_reply":"2023-09-23T21:34:22.337654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # XGBoost Regressor\n# xgb_model = xgb.XGBRegressor(random_state=42)\n# xgb_param_grid = {\n#     'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinking\n#     'max_depth': [3, 4, 5],  # Maximum depth of the tree\n#     'n_estimators': [100, 200, 300],  # Number of boosting rounds\n# }\n# xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=5, scoring='neg_mean_squared_error')\n# xgb_grid_search.fit(X_train, y_train)\n# best_xgb_model = xgb_grid_search.best_estimator_\n# xgb_mse = -cross_val_score(best_xgb_model, X, y, cv=5, scoring='neg_mean_squared_error')\n# xgb_rmse = np.sqrt(xgb_mse.mean())","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:22.34072Z","iopub.execute_input":"2023-09-23T21:34:22.341139Z","iopub.status.idle":"2023-09-23T21:34:22.354877Z","shell.execute_reply.started":"2023-09-23T21:34:22.341105Z","shell.execute_reply":"2023-09-23T21:34:22.353467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Print model performance\n# print(\"Decision Tree RMSE:\", dt_rmse)\n# print(\"Random Forest RMSE:\", rf_rmse)\n# print(\"XGBoost RMSE:\", xgb_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:22.35701Z","iopub.execute_input":"2023-09-23T21:34:22.357917Z","iopub.status.idle":"2023-09-23T21:34:22.371722Z","shell.execute_reply.started":"2023-09-23T21:34:22.357857Z","shell.execute_reply":"2023-09-23T21:34:22.370679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions using the Decision Tree model\ndt_predictions = best_dt_model.predict(X_test)\n\n# Make predictions using the Random Forest model\n# rf_predictions = best_rf_model.predict(X_test)\n\n# Make predictions using the XGBoost model\n# xgb_predictions = best_xgb_model.predict(X_test)\n\n# Evaluate model performance using RMSE\nfrom sklearn.metrics import mean_squared_error\n\ndt_rmse = np.sqrt(mean_squared_error(y_test, dt_predictions))\n# rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n# xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n\n# Print RMSE for each model\nprint(\"Decision Tree RMSE on Test Data:\", dt_rmse)\n# print(\"Random Forest RMSE on Test Data:\", rf_rmse)\n# print(\"XGBoost RMSE on Test Data:\", xgb_rmse)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:22.373174Z","iopub.execute_input":"2023-09-23T21:34:22.374248Z","iopub.status.idle":"2023-09-23T21:34:22.389556Z","shell.execute_reply.started":"2023-09-23T21:34:22.374205Z","shell.execute_reply":"2023-09-23T21:34:22.387989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate RMSE on training data\ndt_train_predictions = best_dt_model.predict(X_train)\n# rf_train_predictions = rf_model.predict(X_train)\n# xgb_train_predictions = xgb_model.predict(X_train)\n\ndt_train_rmse = np.sqrt(mean_squared_error(y_train, dt_train_predictions))\n# rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_predictions))\n# xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_train_predictions))\n\n# Calculate RMSE on test data\ndt_test_predictions = best_dt_model.predict(X_test)\n# rf_test_predictions = rf_model.predict(X_test)\n# xgb_test_predictions = xgb_model.predict(X_test)\n\ndt_test_rmse = np.sqrt(mean_squared_error(y_test, dt_test_predictions))\n# rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_test_predictions))\n# xgb_test_rmse = np.sqrt(mean_squared_error(y_test, xgb_test_predictions))\n\n# Print RMSE for training and test data\nprint(\"Decision Tree RMSE on Training Data:\", dt_train_rmse)\nprint(\"Decision Tree RMSE on Test Data:\", dt_test_rmse)\n# print(\"\\nRandom Forest RMSE on Training Data:\", rf_train_rmse)\n# print(\"Random Forest RMSE on Test Data:\", rf_test_rmse)\n# print(\"\\nXGBoost RMSE on Training Data:\", xgb_train_rmse)\n# print(\"XGBoost RMSE on Test Data:\", xgb_test_rmse)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T21:34:22.391368Z","iopub.execute_input":"2023-09-23T21:34:22.392607Z","iopub.status.idle":"2023-09-23T21:34:22.408007Z","shell.execute_reply.started":"2023-09-23T21:34:22.392566Z","shell.execute_reply":"2023-09-23T21:34:22.406856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If RMSE on training data is significantly lower than RMSE on test data, it indicates that we are not overfitting. In this case, we are good.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}